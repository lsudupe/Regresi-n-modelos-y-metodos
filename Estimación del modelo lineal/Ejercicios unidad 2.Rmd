---
title: "Estimación del modelo lineal ejercicios"
author: "Laura Sudupe Medinilla"
date: "1/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup, echo = FALSE, message = FALSE}
# Función para cargar todos los paquetes necesarios
LoadLibraries <- function() {
  myLibraries <- c("faraway", "ggplot2", "reshape2")
  invisible(lapply(myLibraries, library, character.only = TRUE))
}
LoadLibraries()
```


# Ejercicios faraway

## 1.
  The dataset teengamb concerns a study of teenage gambling in Britain. Fit a 
  regression model with the expenditure on gambling as the response and the sex, 
  status, income and verbal score as predictors. Present the output.
```{r}
#ajustamos los datos al modelo
lm <- lm(gamble ~ sex + status + income + verbal, data=teengamb )
lmsum <- summary(lm)
lmsum
```
  (a) What percentage of variation in the response is explained by these 
  predictors?
```{r}
#El coeficiente de determinación R^2 es igual al cuadrado de la correlación del 
#coeficiente. Cuando se expresa en porcentaje, R^2 representa el porcentaje de
#variación en la variable dependiente y puede ser explicado mediante la 
#variación en la variable independiente x mediante la linea de regreión.

(lmsum$r.squared)*100
```
    (b) Which observation has the largest (positive) residual? Give the case 
  number.
```{r}
residuos <- lmsum$residuals
max(residuos)      #valor residuo maximo
which.max(residuos) #observacion con el maximo valor
```
  (c) Compute the mean and median of the residuals.
```{r}
#Han de dar valores entorno al cero, el hecho de que no den es debido a errores
#de calculo
mean(residuos)
median(residuos)
```
  (d) Compute the correlation of the residuals with the fitted values.
```{r}
cor(fitted(lm), resid(lm))
```
  (e) Compute the correlation of the residuals with the income.
```{r}
cor(resid(lm), teengamb$income)
```
  
  (f) For all other predictors held constant, what would be the difference in 
  predicted expenditure on gambling for a male compared to a female?
```{r}
lmsum
lm$coefficients["sex"]
```
  Estos datos nos indican la pendiente de la recta, por lo tanto, la diferencia
  entre "expenditure on gambling in punds per year" es 22.12 "pounds" distinta
  para los hombres que para las mujeres. Menor para las mujeres (sex=1)
  

## 2.
  The dataset uswages is drawn as a sample from the Current Population Survey in
  1988. 
  a) Fit a model with weekly wages as the response and years of education and
  experience as predictors. 
  
```{r}
lm2 <- lm(wage ~ educ + exper, data = uswages)
summary(lm2)
```
  b) Report and give a simple interpretation to the regression coefficient for 
  years of education. Now fit the same model but with logged weekly wages. 
```{r}
lm2$coefficients
```
  El ajuste no es muy bueno, tenemos un $R^2$ bajo y un error estandar elevado.
  
  Los coeficientes nos indican que el sueldo (wage) depende de la educación 
  recibida y la experiencia. La relación es de 51.18 unidades mas de educación 
  por cada wage y 9.77 unidades mas de experiencia por cada wage. Esto quiere
  decir que hay un aumento de 51.18 unidades en el salario por cada año de 
  educación y un aumento de 9.77 unidades en el salario por cada año de 
  experiencia.
  
  $$wage = -242.8 + 51.17educ + 9.77expe$$
  
```{r}
#modificamos los datos de waeg logaritmicamente
lmlog2 <- lm(log(wage) ~ educ + exper, data = uswages)
summary(lmlog2)
lmlog2$coefficients
```
 Vemos que $R^2$ ha aumentado ligeramente y el error estandar a bajado 
 considerablemente.
 
 La relación entre los coeficientes es la siguiente
 
 $$\log(wage) = 4.65 + 0.09educ + 0.02expe$$
  c)Give an interpretation to the regression coefficient for years of education.
  Which interpretation is more natural?
  No entiendo lo que se me pide
  
  
## 4.
  The dataset prostate comes from a study on 97 men with prostate cancer who 
  were due to receive a radical prostatectomy. Fit a model with lpsa as the 
  response and lcavol as the predictor. Record the residual standard error and 
  the R2
```{r}
lm4 <- lm(lpsa ~ lcavol, data=prostate)
summary(lm4)
```
```{r}
#Error estandar de los residups
res4.1 <- summary(lm4)$sigma

#R^2, coeficiente de determinación
coef4.1 <- summary(lm4)$r.squared
```
  . Now add lweight, svi, lbph, age, lcp, pgg45 and gleason to the model one at 
  a time. For each model record the residual standard error and the R2
```{r}
lm4.2 <- update(lm4,. ~. + lweight)
res4.2 <- summary(lm4.2)$sigma
coef4.2 <- summary(lm4.2)$r.squared

lm4.3 <- update(lm4.2,. ~. + svi)
res4.3 <- summary(lm4.3)$sigma
coef4.3 <- summary(lm4.3)$r.squared

lm4.4 <- update(lm4.3,. ~. + lbph)
res4.4 <- summary(lm4.4)$sigma
coef4.4 <- summary(lm4.4)$r.squared

lm4.5 <- update(lm4.4,. ~. + age)
res4.5 <- summary(lm4.5)$sigma
coef4.5 <- summary(lm4.5)$r.squared

lm4.6 <- update(lm4.5,. ~. + lcp)
res4.6 <- summary(lm4.6)$sigma
coef4.6 <- summary(lm4.6)$r.squared

lm4.7 <- update(lm4.6,. ~. + pgg45)
res4.7 <- summary(lm4.7)$sigma
coef4.7 <- summary(lm4.7)$r.squared

lm4.8 <- update(lm4.7,. ~. + gleason)
res4.8 <- summary(lm4.8)$sigma
coef4.8 <- summary(lm4.8)$r.squared


reserror <- c(res4.1, res4.2, res4.3, res4.4, res4.5, res4.6, res4.7, res4.8)
coef <- c(coef4.1, coef4.2, coef4.3, coef4.4, coef4.5, coef4.6, coef4.7, coef4.8)
variables <- (1:8)


```
  
  . Plot the trends in these two statistics.
```{r}
data <- data.frame(variables, reserror, coef)

data <- melt(data, id="variables")

ggplot(data=data, aes(x=variables, y=value, colour=variable)) +
  geom_line()
        
```
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  